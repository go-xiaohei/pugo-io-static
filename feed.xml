<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"><channel><title>Pugo.Static - site generator</title><link>http://localhost</link><description>pugo is a simple static site generator</description><lastBuildDate>Mon, 07 Dec 2015 14:58:37 +0800</lastBuildDate><item><title>Welcome</title><link>http://localhost/2015/11/28/welcome.html</link><pubDate>Sat, 28 Nov 2015 00:00:00 +0000</pubDate><category>pugo</category><category>welcome</category><description><![CDATA[ <p>When you read the blog, <code>pugo</code> is running successfully. Then enjoy your blog journey.</p>

<p>This blog is generated from file <code>source/welcome.md</code>. You can learn it and try to write your own blog article with following guide together.</p>

<h4>blog meta</h4>

<p>Blog&rsquo;s meta data, such as title, author, are created by first <code>ini</code> section with block <strong>```ini &hellip;.. ```</strong>:</p>
<pre><code class="language-ini">; post title, required
title = Welcome to Pugo.Static

; post slug, use to build permalink and url, required
slug = welcome-pugo-static

; post created time, support
; 2015-11-28, 2015-11-28 12:28, 2015-11-28 12:28:38
date = 2015-11-28 11:28

; post updated time, optional
; if null, use created time
update_date = 2015-11-28 12:28

; author identifier, reference to meta.md [author.pugo], required
author = pugo-robot

; tags, optional
tags = pugo,welcome
</code></pre>

<h4>blog content</h4>

<p>Content are from the second section as <code>markdown</code> format:</p>
<pre><code class="language-markdown">When you read the blog, `pugo` is running successfully. Then enjoy your blog journey.

This blog is generated from file `source/welcome.md`. You can learn it and try to write your own blog article with following guide together.

...... (markdown content)
</code></pre>

<p>Just write content after blog meta, all words will be parsed as markdown content.</p>
 ]]></description></item><item><title>阅读 valyala/fasthttp —— 比官方库更快的 HTTP 包</title><link>http://localhost/2015/11/25/deep-in-fasthttp-package.html</link><pubDate>Wed, 25 Nov 2015 10:58:59 +0000</pubDate><category>Go</category><category>Http</category><description><![CDATA[ <p><a href="https://github.com/valyala/fasthttp">valyala/fasthttp</a> 是号称比官方<code>net/http</code>库更快的 http server 库。就去顺便研究了，发现一些细节的不同。</p>

<h3>处理 net.Conn 的 goroutine</h3>

<p><strong>处理net.Conn的goroutine的使用方式</strong>，和标准库有很大差别。在标准库，<code>net.Listener.Accept()</code> 到一个连接，就会开启一个goroutine：</p>
<pre><code class="language-go">// Serve accepts incoming connections on the Listener l, creating a
// new service goroutine for each.  The service goroutines read requests and
// then call srv.Handler to reply to them.
func (srv *Server) Serve(l net.Listener) error {
    defer l.Close()
    var tempDelay time.Duration // how long to sleep on accept failure
    for {
        rw, e := l.Accept()
        if e != nil {
            ......
        }
        ......
        c, err := srv.newConn(rw)
        if err != nil {
            continue
        }
        c.setState(c.rwc, StateNew) // before Serve can return
        go c.serve() // 在这里创建一个goroutine处理net.Conn的实际逻辑
    }
}
</code></pre>

<p>但是在<code>valyala/fasthttp</code>中使用的是worker的形式，开启固定数量的goroutine处理<code>net.Conn</code>。</p>

<!--more-->

<p><a href="https://github.com/valyala/fasthttp/blob/52c04f13b2bbb0a9c361825ee9b1c7306f5f0910/server.go#L582">server.go#L582</a>:</p>
<pre><code class="language-go">func (s *Server) Serve(ln net.Listener) error {
    var lastOverflowErrorTime time.Time
    var lastPerIPErrorTime time.Time
    var c net.Conn
    var err error

    maxWorkersCount := s.getConcurrency() // 获取worker的并发数
    // 创建一个worker池
    wp := &amp;workerPool{
        WorkerFunc:      s.serveConn, // 每个net.Conn的处理逻辑
        MaxWorkersCount: maxWorkersCount,
        Logger:          s.logger(),
    }
    // 开启worker内池中处理chan的清理，处理掉没有在处理请求的chan
    wp.Start()

    for {
        // 从listener收到net.Conn
        // 这个里面做的IP连接数量控制，超过会返回错误
        if c, err = acceptConn(s, ln, &amp;lastPerIPErrorTime); err != nil {
            wp.Stop()
            if err == io.EOF {
                return nil
            }
            return err
        }
        // 让worker池去处理net.Conn
        if !wp.Serve(c) {
            c.Close()
            if time.Since(lastOverflowErrorTime) &gt; time.Minute {
                s.logger().Printf(&quot;The incoming connection cannot be served, because %d concurrent connections are served. &quot;+
                    &quot;Try increasing Server.Concurrency&quot;, maxWorkersCount)
                lastOverflowErrorTime = time.Now()
            }
        }
        c = nil
    }
}
</code></pre>

<p>下一步就是 <code>wp.Serve(c)</code>，在 <a href="https://github.com/valyala/fasthttp/blob/52c04f13b2bbb0a9c361825ee9b1c7306f5f0910/workerpool.go#L92">workerpool.go#L92</a>:</p>
<pre><code class="language-go">func (wp *workerPool) Serve(c net.Conn) bool {
    ch := wp.getCh() // 从worker里获取一个workChan
    if ch == nil {
        return false
        // 如果获取不到workChan，返回false
        // 上面的代码提示错误，超过并发量了
    }
    ch.ch &lt;- c
    return true // 把net.Conn扔进workChan的chan中
}
</code></pre>

<p>之后来看怎么获取一个<code>workChan</code>，在<a href="https://github.com/valyala/fasthttp/blob/52c04f13b2bbb0a9c361825ee9b1c7306f5f0910/workerpool.go#L101">workerpool.go#L101</a>:</p>
<pre><code class="language-go">func (wp *workerPool) getCh() *workerChan {
    var ch *workerChan
    createWorker := false

    wp.lock.Lock()
    chans := wp.ready
    n := len(chans) - 1
    // 尝试获取wp.ready中空闲的workChan
    if n &lt; 0 {
        // 没有空闲的workChan，需要新建
        if wp.workersCount &lt; wp.MaxWorkersCount {
            createWorker = true
            wp.workersCount++
        }
    } else {
        // 从wp.ready空闲的workChan中取出最后一个
        ch = chans[n]
        wp.ready = chans[:n]
    }
    wp.lock.Unlock()

    if ch == nil {
        if !createWorker {
            return nil
        }
        // 从公共池中取出一个workChan来用
        vch := workerChanPool.Get()
        if vch == nil {
            // 公共池里都没有，创建一个新的
            vch = &amp;workerChan{
                ch: make(chan net.Conn, 1),
            }
        }
        ch = vch.(*workerChan)
        // 在一个goroutine里处理workChan
        go func() {
            // 开始读取操作这个workChan
            wp.workerFunc(ch)
            // workChan用完了放回公共池
            workerChanPool.Put(vch)
        }()
    }
    return ch
}
</code></pre>

<p>上面看到<code>ch.ch &lt;- c</code>，将<code>net.Conn</code>扔进了workChan的chan中。chan的处理逻辑在<code>wp.workerFunc(ch)</code>，在<a href="https://github.com/valyala/fasthttp/blob/52c04f13b2bbb0a9c361825ee9b1c7306f5f0910/workerpool.go#L152">workerpool.go#L152</a>：</p>
<pre><code class="language-go">func (wp *workerPool) workerFunc(ch *workerChan) {
    var c net.Conn
    var err error
    ......
    for c = range ch.ch {
        if c == nil { // 这里注意，传入nil就跳出循环，不处理这个workChan
            break
        }
        // 调用WorkerFunc处理每个net.Conn
        // 这个WorkerFunc在上文代码有，
        // WorkerFunc:s.serveConn
        if err = wp.WorkerFunc(c); err != nil &amp;&amp; err != errHijacked {
            errStr := err.Error()
            if !strings.Contains(errStr, &quot;broken pipe&quot;) &amp;&amp; !strings.Contains(errStr, &quot;reset by peer&quot;) {
                wp.Logger.Printf(&quot;error when serving connection %q&lt;-&gt;%q: %s&quot;, c.LocalAddr(), c.RemoteAddr(), err)
            }
        }
        if err != errHijacked {
            c.Close()
        }
        c = nil

        // 记得用完了放到wp.ready切片中
        // 以便重复使用
        if !wp.release(ch) {
            break
        }
    }
}
</code></pre>

<p>看到这里就可以总结一下。<code>valyala/fasthttp</code>其实是把<code>net.Conn</code>分配到一定数量的goroutine中执行，而不是一对一。换句话说，当goroutine数量巨大的时候，上下文切换成本开始有明显的性能影响。标准库在并发量很大的时候面临这个问题。<code>valyala/fasthttp</code>就使用了worker规避这个问题。goroutine本身就是轻量级的协程，可以即开即用。worker尽量重用每个goroutine，从而可以控制住goroutine的数量（默认的最大chan数量为256×1024）。而且如果http请求阻塞，会霸占<code>workChan</code>，直到把worker里的<code>workChan</code>耗尽（有keepAlive超时配置来处理这个问题）。</p>

<p>另外一个发现是<code>*RequestCtx</code>上下文的池。</p>

<h3>*RequestCtx 的池</h3>

<p>标准库里对于类似的http请求上下文用的是<code>*http.response</code>这个对象，问题是每次都是新的。</p>
<pre><code class="language-go">// Serve a new connection.
func (c *conn) serve() {
    ......

    for {
        // 这里返回的是*http.response
        w, err := c.readRequest()
        if c.lr.N != c.server.initialLimitedReaderSize() {
            // If we read any bytes off the wire, we're active.
            c.setState(c.rwc, StateActive)
        }
        ......

        // 要求实现的 http.Handler 接口
        // 在这里被使用
        serverHandler{c.server}.ServeHTTP(w, w.req)

        ......
    }
}
</code></pre>

<p><code>valyala/fasthttp</code>类似的结构<code>*RequestCtx</code>用的是池，<a href="https://github.com/valyala/fasthttp/blob/52c04f13b2bbb0a9c361825ee9b1c7306f5f0910/server.go#L743">server.go#L743</a>有：</p>
<pre><code class="language-go">ctx := s.acquireCtx(c)

// 其实就是:
func (s *Server) acquireCtx(c net.Conn) *RequestCtx {
    v := s.ctxPool.Get()
    var ctx *RequestCtx
    if v == nil {
        ctx = &amp;RequestCtx{
            s: s,
        }
        ctx.v = ctx
        v = ctx
    } else {
        ctx = v.(*RequestCtx)
    }
    ctx.initID()
    ctx.c = c
    return ctx
}
</code></pre>

<p><code>*RequestCtx.Request</code>和<code>*RequestCtx.Response</code>支持reset，使更安全的使用，比如 <a href="https://github.com/valyala/fasthttp/blob/52c04f13b2bbb0a9c361825ee9b1c7306f5f0910/server.go#L776">server.go#L776</a>有：</p>
<pre><code class="language-go">err = ctx.Request.Read(br)

// 就是
func (req *Request) Read(r *bufio.Reader) error {
    req.clearSkipHeader()
    err := req.Header.Read(r)
    if err != nil {
        return err
    }

    if req.Header.IsPost() {
        req.body, err = readBody(r, req.Header.ContentLength(), req.body)
        if err != nil {
            req.Reset()
            // 出错了要reset，用完了的时候同时也要
            // 在L1030，releaseReader 方法
            // 其实就是把r这个 *bufio.Reader 直接 Reset 再放回公共池
            // 下次用的时候有一个 *bufio.Reader
            return err
        }
        req.Header.SetContentLength(len(req.body))
    }
    return nil
}
</code></pre>

<p>总的来说，用池来来减少对象数量，也是增强性能最常见的方法。标准库和 <code>valyala/fasthttp</code> 都对 <code>*bufio.Reader</code> 和 <code>*bufio.Writer</code> 做了池的处理。不过对于频繁存取的服务，池的效率提升比较有限。而且<code>sync.Pool</code>没有容量控制，有时会变得不可控，需要注意一下。</p>

<h5>Thanks</h5>

<p>上文是在 <strong>Go实践群(386056972)</strong> 和群友讨论时顺便深入阅读的结果。感谢群友 <a href="http://blog.rootk.com/">华子</a> 的支持。</p>
 ]]></description></item><item><title>Gopher China 大会</title><link>http://localhost/2015/4/29/gopher-china-2015.html</link><pubDate>Wed, 29 Apr 2015 00:00:34 +0000</pubDate><category>Go</category><description><![CDATA[ <p>前两天去上海参加 <a href="http://gopherchina.org"><strong>Gopher China 2015</strong></a> 大会，见到很多久闻大名的大神和朋友，感觉很好。而且看到许多的企业，尤其是大企业都已经开始成规模的使用 golang，说明 golang 本身的设计和性能，已经受到了大家的认可。当然其实有很多的话题，不局限在 golang 了。</p>

<!--more-->

<h2>Go 语言核心</h2>

<p>最重量级的话题，就是 <a href="http://weibo.com/qyuhen">雨痕</a> 的 《Go 1.4 Runtime》。主要说了 Go 的内存分配器、垃圾回收器和goroutine调度器三块内容。我之前阅读过他的 <a href="https://github.com/qyuhen/book">《Go 语言笔记》</a> ，非常不错。很详细的阐述了 Go 语言本身的实现设计，同时为更合理的利用 golang 提供一些参考。 再加上他本人也很低调，真的是 <strong>隐士高人</strong> 的感觉。这次的他的演讲也相当不错。流畅的思路和平和的语言，而且不时的有诙谐幽默，让人听起来很有意思。唯一的遗憾是，他准备的ppt其实可以讲到3个小时，可惜会程只有45min，尽管大家还是争取多听了一些，但还是意犹未尽。</p>

<p>另一个超级话题，是 Robert Griesemer 的演讲。他是 Go 的三位作者之一，也是 Google V8 和 Java Hotspot VM 开发者之一，相当巨大的光环！他的演讲是关于 <a href="https://golang.org/cmd/gofmt/">gofmt</a> 的。 Go语言本身有很多的外围工具，比如 gofmt, godoc。其中格式化工具 gofmt 帮助大家简单直接的就统一了代码风格。Go 本身就带有 parser 包，就能够很好的去解析go源码到语法树。 唯一要吐槽的是 Q&amp;A 环节，提问的童鞋用谁都听不懂的“英语”去问，哈哈哈！</p>

<h2>Go 和 高速并发</h2>

<p>很多人看上 Go 语言，主要是因为简化的并发模型：很简单地创建轻量级的用户协程goroutine，使用channel进行goroutine之间的通信，runtime本身的调度足够快。当然在演讲的题目里不会少，比如 <a href="http://weibo.com/unbe"><strong>达达</strong></a> 聊了在游戏中的实践，<a href="http://weibo.com/chuangyiyongpin"><strong>goroutine</strong></a>(codis的作者) 和 <strong>周洋</strong> 在分布式系统中的实现，<a href="http://weibo.com/qleelulu"><strong>QLeeLuLu</strong></a>(fawave的作者)在广告竞价系统中的应用，以及 <strong>月牙寂</strong> 的在P2P缓存网络的应用。</p>

<p>总结起来，高速并发时需要考虑的细节：</p>

<ul>
<li>数据里CPU的距离</li>
</ul>

<p>达达的游戏项目为了保证很高的速度，很多的数据都直接是内存数据。内存中的大数据会明显的影响GC的效率。因而要做的， <strong>减少内存中的数据对象数量</strong>。然后内存数据肯定是要写入物理存储的。达达在内存做了一层数据到mysql的直接映射关系，被称为 <strong>内存数据库</strong>，而且支持事务处理。我的理解，内存数据库中的实际操作，不是直接对mysql的操作copy过来。它本身的模型并不复杂，所以很多的操作都是单一对象操作的，或者是对象的某些字段的操作。达达也提起内存数据库的调度代码其实是用代码生成的。换句话说就是简单的逻辑描述就可以表示的数据操作。那么事务显然在业务中是必要的，同时操作不同对象，相当于操作多个数据表。</p>

<p>另外这个内存数据库使用了类似传统数据库的日志机制。内存的修改是可以即时完成的，然后同步到mysql用的是自定义的一种事务日志描述。mysql其实也是把当前执行的操作写在binlog中，后续才会真正执行到存储的数据中。</p>

<ul>
<li>适当的集中处理</li>
</ul>

<p>集中的反义，就是分散。分散的理解，其实有很多可能。比如反复的io操作，rpc操作等。从go本身的角度，分散的造成的麻烦是 <strong>goroutine泄漏</strong> 。如果把各种逻辑都放到独立的goroutine中，当逻辑阻塞，goroutine就不停创建且无法结束。这给调度器带来很大的压力，以至于别的逻辑创建的goroutine很久无法被执行，拖慢整个业务的速度。简单的处理方式就是通过channel，将需要处理的逻辑传递给某些goroutine执行。换句话说，创建一些goroutine专门处理某种逻辑，通过channel传递逻辑参数，就可以。</p>

<p>剩下的问题就是对外部资源调度的分散。redis使用时最常见的集中的方法就是用pipeline。rpc也可以使用长链接双工模式的调用。简单地说就是让各种命令一起执行，而不是分别执行。</p>

<ul>
<li>控制锁和timer</li>
</ul>

<p>锁在很多排他性的操作的时候是必须的，没有任何办法规避。但是 <strong>锁的粒度</strong>，是需要控制的关键。如果锁的粒度很大，锁住的数据或者逻辑很多，那别的操作就只能等待。比如说，一个10k对象的全局map修改，需要加锁防止并发冲突。但是只要锁住1W的对象就全部无法操作。因此最简单把这个10k个对象的map拆分成10个1K的map。这样每个小map即使锁住，也只会影响1k数据，而不是原来的10k。但实际中锁的粒度，需要根据业务判断，但是减小粒度是统一的追求。</p>

<p>timer这东西其实就是一个计时的goroutine和到期信号的channel的组合。timer越多显然就是goroutine越多。调度器的消耗明显增长。如果还是需要计时逻辑的操作，可以去看看时间轮算法，减少创建timer。另外就干脆不要用，在自己的逻辑中判断时间是否超出限制的问题。</p>

<ul>
<li>总结</li>
</ul>

<p>高并发的服务，Go 本身的一些细节，是有助于提升效率的，但是不是靠 Go 语言本身就足够，还需要和各种手段配合，才能真正满足实际的业务要求。</p>

<h2>Go 和 虚拟化</h2>

<p>Go 语言最明星的项目是 <a href="http://www.docker.com"><strong>docker</strong></a>。很多大神在研究和使用docker。作为一种轻量级的虚拟化技术，相比xen有很多优点，受到大家的青睐。我并不熟悉docker的应用，没有在虚拟化上有多少实际经验，所以听听大神们的说法，增长知识。</p>

<p><a href="http://weibo.com/genedna"><strong>马全一</strong></a> 是docker社区很有名的朋友。他演讲主要再说DevOps，就是从开发、测试到部署、运维的全程解决方案。为了在开发、测试和部署层面的统一，系统环境需要很好的统一性。直接方法就是虚拟化，如完全类似的虚拟镜像。docker的出现，让虚拟化的成本大大的降低。而且docker镜像的管理非常像git样版本管理的模式，对开发人员非常友善。另外，docker镜像对系统资源的使用很有效率，也可以作为生产部署方式。因而，以后的DevOps的趋势很可能就是ContainerOps。</p>

<p>我不太懂docker，听了很多未来的趋势，以及docker和rocket之间的江湖恩怨。目前较好的使用方式就是用docker虚拟化application，<strong>不要虚拟数据存储</strong>。就很像nginx代理n个实例，这些实例操作统一数据的感觉。另外，演讲也提到微软Windows对docker的支持。十几天前docker也发布的windows客户端的preview。看来docker在全平台的虚拟化很有希望了。</p>

<h2>Go 与各种领域</h2>

<p>Go 语言的定位是系统级语言，很多方面都会有深入的应用。</p>

<p>一个演讲是有关在电信领域，网络功能虚拟化(NFV, network functions virtualization)。电信网络设备之间的连接，是网络单元之间的连接，如基站-节点设备-网关设备，各种物理设备组成的网络。物理设备之间的沟通，就需要靠硬件协议交互。网间设备种类越多，交互协议就越多越复杂。Go的使用，就是在普通服务器设备上，实现网络单元的功能，即软件模拟硬件。同时，虚拟后的软件相比硬件设备，可以更快平衡网络的突然变化。不过，电信网络对联通率，联通质量有很严格的要求，目前这个方案还是测试阶段，不知道成功与否。</p>

<p>另外有个金融领域的演讲，补充了很多知识。以前我也以为金融系统，尤其是银行系统是很古老的系统。但是其实他们也在随着新的技术演进。因为金融领域的特殊性，对数据的安全和监管要求很高。而且金融业务的复杂度远超过一般商业业务。金融IT系统本身是完全耦合的，而且架构非常稳定。当然，他们也在尝试使用虚拟化技术，来做架构内部的调整。虽然整体结构是不太可能改变的，但是各种新兴业务也在使用新的技术。</p>

<p>还有一个很有启发的演讲，用 Go 语言写的网络操作系统，类似于 Chrome OS。我们为何要考虑高并发的问题，因为服务和运算都是集中的，比如微博的数据处理就是新浪机房在做。那如果去掉中心，那运算的复杂度显然会降低很多。同时，数据也会分散，分布在各个客户端节点中。这其实很像比特币，没有中心，数据都存在用户的客户端。数据的更新通过客户端的P2P传播。类比的说，新浪的数据其实分布在各个微博用户的电脑上。当你使用微博，就其实连入了微博网路，可以P2P的从别的客户端同步你需要的数据（一般只需要自己时间轴的数据）。这是我的理解，不知道是不是大神真正的意思。目前来思考，其实还有很多问题，比如数据的分散和同步，网络节点同步等等问题。不过这样的一种模式，确实很有开创性。</p>

<!--#### 一个小失望

七牛是 Go 语言在中国商用的先驱。许式伟也是 Go 语言最早的使用者和布道者之一。只是这次就聊个 HTTP 测试工具，实在是让人失望。亮点也就只有发明一种 DSL 来简化HTTP测试的描述。七牛本来也有很多可以聊的，比如云存储的冗余机制，多媒体文件的处理。所以，他来说这样的题目，实在是失望。-->

<h2>许多朋友</h2>

<p>在 Go 语言圈里混了很久，也算有很多熟人。以前都是网上聊天讨论，这次可以见到本人，非常高兴。达达和月牙寂是厦门本地的朋友，偶尔也见面聊天，还是很熟悉的。不过两个人在线下的感觉和上台演讲不同，达达还是太羞涩啦。</p>

<p><a href="https://github.com/lunny">lunny</a>是xorm的作者，看起来是个很温存的大叔。<a href="https://github.com/blackbeans">BetaGo</a>好高啊，很认真的样子。<a href="https://github.com/Terry-Mao">毛剑</a>也有点软软的感觉。当然<a href="http://weibo.com/533452688">asta谢</a>的观感和照片里差不多，很热情很热心，还辛苦的为提问的童鞋递话筒。大会也一直是他辛辛苦苦，忙前忙后。是个很不错的人。</p>

<p>我只是个普通的程序员，没什么高大上的作品或者名号，也不求成为大家眼中的大神。了解和学习我想要的，做好自己的工作，过好朴素的生活，我就满足了。</p>

<p>Go 语言在中国非常火热。国内大量的 Go 语言开发者在这次 gopher china上聚会，交流技术，结交朋友。我也看到其实还有很多的大神在深入研究 Go 语言的使用。我还只是一个才入门的孩子，需要很多锻炼。希望自己再接再厉，好好学习，天天向上！！！</p>
 ]]></description></item><item><title>2014, 2015</title><link>http://localhost/2015/2/22/2014-2015.html</link><pubDate>Sun, 22 Feb 2015 22:58:59 +0000</pubDate><description><![CDATA[ <p>2014年已经过去，2015已然开始。时光流逝，很多故事已经发生，我却不知从何说起。一切都按照预想进行，工作事业都很顺利。尤其是从西安到厦门重新谋生的过程，和之前预想的情况相差不大。只是不知为何，心里还是 <strong>空荡荡</strong> 的。我已经虚岁25了，越长大越孤单。也许，该是找个伴儿的时候了。</p>

<h2>2014</h2>

<p>2014是本命年，我都做了些什么。生活好像变化很大。可是，细细想来，还值钱没有太大差别：一个人的出租屋，一个人的死宅，公司宿舍的两点一线。我可能习惯了这样的生活。</p>

<p>其实这样也对。从西安到了厦门，最大的期望就是恢复到原来简单的生活：工作兢兢业业，生活波澜不惊。按照计划，我已经做到了。入职<a href="http://www.yunduo.com">云朵网络</a>后工作顺利，没有很多的波澜。我了解、熟悉并加入到整个项目，各种问题中稳步推进，效果良好。云朵有几十名员工，分属各个部门。我作为后端开发，经常和测试妹子们和硬件开发们交流探讨。这也算逐渐熟悉了同事们。总之，现在的工作环境，我是<strong>满足</strong>的。&lt;!&ndash;more&ndash;&gt;</p>

<p>生活上，相对于之前的死宅，我有一点点的开放。有几次面基，吃吃饭爬爬山。更多几次电影，跟上一些影视圈的步伐。不过，也就这么多了吧。我终究还是一个<strong>不愿意交际</strong>的人。这可能是我更落寞的原因。西安还有几个很熟悉的朋友，偶尔聊聊深沉的心里话。来到厦门的时间不长，还没有培养出这样的朋友。同时，我不是性格张扬的人。当自己心情不好的时候，并不会形于色，而是藏在心里。<strong>伪装</strong>是必须的，不为了应付别人，而是为了宽慰自己。</p>

<hr />

<p>2014年里，<a href="http://gogs.io">Gogs</a> 的进度没有实现年初制定的roadmap。原本计划2015年春节前发布 v1.0。可惜现在 v0.6 还没完全搞定。不过，<a href="http://wuwen.org">无闻</a> 说的5000+ Star倒是做到了。猛然间，我参与了如此受关注的项目，真是倍感压力。我知道，自己能力有限水平一般，希望2015年能继续参与下去，尽心尽力吧！</p>

<p>到厦门后，我在 <a href="https://github.com/fuxiaohei">Github</a> 的活跃度就下降了很多。一方面是这边的工作时间更多，自由时间更少了。另一方面，是忽然间没有了很多的热情。我的心思用在应付新城市的生活上，没有更多的精力专心在开源项目。经过这半年，工作和生活都稳定下来啦，也有余力继续。</p>

<p>如今，Github 上的活动已经成为判断一个程序猿技术能力的重要方面。一直以来我都在放出一些学习的代码，比如一个自己写着玩的php框架，php博客，以及一个Golang的博客<a href="https://github.com/fuxiaohei/Goblog">GoBlog</a>。后来，GoBlog的用户群逐渐出现。如今我已知的用户有十来位朋友。也许我需要深入的考虑这个东西，如何从一个玩具到一个产品。我有个想法：“做好这个东西，对得起这些支持我的朋友们”。哈哈，不错不错！</p>

<h2>2015</h2>

<p>智能穿戴设备领域的竞争越来越激烈。我们公司的产品要如何做好，必然需要一些过人之处。这些优势最终落地在各种技术支持上。因而，新的一年，我要做的还有很多。虽然我不知道会有怎样的新的内容，但是显然它不会是简单的工作。给自己一点鼓励，加油！</p>

<p>Gogs 今年的roadmap还没有出来，不知道工作量会有多少。另外，我打算用 <a href="http://semantic-ui.com">SemanticUI</a> 和 <a href="http://facebook.github.io/react/">React.js</a> 来重构整个前端架构。我需要学习这两个新事物，并学以致用。努力努力。</p>

<h2>别的话</h2>

<p>对于一个伴侣，我有一些开放，有一些保守。比如性别无所谓，年龄要相近&hellip;&hellip;这些表象的东西在乎的不是那么多。有人说，人一辈子遇到的只有两种人：吵过后离开的人，吵过后凑合着过的人。从我父母的婚姻来看，凑合着过的，是大多数吧。就像我妈说的，难道还能离啊！哈。</p>

<p>为什么会凑合着过？因为放下了很多本来的期望。就像本来需要一个高富帅，后来发现一个不高不富不帅的对自己好，也就算了。人总会审时度势。不过说的难听一点，就是得过且过，懒得再找。</p>

<p>我不是一个积极的人。我交际上不积极，认识的人不多，更不要说有更多深入想法的人。心态上我也不积极，所有的悲与痛我都藏在心里。对外嘻嘻哈哈，对内郁结难久。从历史到现在，很多的事情在心里结痂。我不愿意去解开他们，反而在享受他们带来的悲伤和孤寂。蔡说，我是一个<strong>别扭</strong>的人。</p>
 ]]></description></item></channel></rss>